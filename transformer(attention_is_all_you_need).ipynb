{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rachit2005/Transformer/blob/main/transformer(attention_is_all_you_need).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH8qL7QNSqL_"
      },
      "source": [
        "dmodel = 512 --> in paper , it represents the size of the embedding vector of each word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRNXIrznd0um"
      },
      "source": [
        "Input Embedding --> the process of converting input text (words or subwords) into numerical vectors, capturing their semantic meaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxkD9sLMX9_9",
        "outputId": "2dee72d6-1cdc-4401-ee79-91a5bbe3529c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1JFssj91PSB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import math\n",
        "\n",
        "class InputEmbedding(nn.Module):\n",
        "  def __init__(self, d_model:int, vocab_size:int):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.embedding(x) * math.sqrt(self.d_model) # given in paper under Embedding and Softmax title"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mrcA5yGd3RL"
      },
      "source": [
        "Positional Embedding --> a technique used to inject information about the position of words in a sequence into the model's architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwlvzKYwdm9b"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self , d_model,seq_length , dropout):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.seq_length = seq_length\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    # create a matrix of shape (seq_length , d_model)\n",
        "    pe = torch.zeros(seq_length ,d_model)\n",
        "    # create a vector which represent the position of the word in the sentence\n",
        "    position = torch.arange(0,seq_length, dtype=torch.float).unsqueeze(1) # --> shape : [seq_length , 1]\n",
        "    div_term = torch.exp(torch.arange(0 , d_model , 2).float()*(-math.log(10000)/d_model)) # --> shape : [d_model/2]\n",
        "    # apply the sin to even pos and cos to odd pos\n",
        "    pe[:,0::2] = torch.sin(position * div_term) # --> all the columns with rows from 0 with step of 2\n",
        "    pe[:,1::2] = torch.cos(position * div_term)\n",
        "\n",
        "    # now we add the batch dimension to apply to whole sentences\n",
        "    pe = pe.unsqueeze(0) # --> shape: [1,seq_length , d_model]\n",
        "    self.register_buffer('pe' , pe)\n",
        "\n",
        "  def forward(self , x):\n",
        "    # x.shape --> [batch_size, seq_length, d_model]\n",
        "    x = x + (self.pe[: , :x.shape[1] , :]).requires_grad_(False)\n",
        "    return self.dropout(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzMyUKM7kAve"
      },
      "source": [
        "Layer Normalization --> normalization technique like batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ngY7cxIj8RO"
      },
      "outputs": [],
      "source": [
        "class LayerNormalization(nn.Module):\n",
        "  def __init__(self , epsilon:float = 10**-6):\n",
        "    super().__init__()\n",
        "    self.eps = epsilon\n",
        "    # nn.Parameter --> it is a special tensor that tells the model that it is a learnable parameter\n",
        "    self.gamma = nn.Parameter(torch.ones(1))\n",
        "    self.beta = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "  def forward(self , x):\n",
        "    mean = x.mean(dim=-1 , keepdim=True)\n",
        "    std = x.std(dim=-1 , keepdim=True)\n",
        "\n",
        "    gamma = self.gamma.to(x.device)\n",
        "    beta = self.beta.to(x.device)\n",
        "\n",
        "    return gamma*(x-mean)/(std + self.eps) + beta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYSUl-zhmDWe"
      },
      "source": [
        "Feed Forward Layer --> This consists of two linear transformations(W1 , W2 , b1 , b2) with a ReLU activation(max-function) in between.\n",
        "\n",
        "FFN(x) = max(0xW1 +b1)W2 +b2\n",
        "\n",
        "and the first layer in from d_model to d_ff and then the other one is from d_ff to d_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7nvrED0l5eQ"
      },
      "outputs": [],
      "source": [
        "class FeedForwardLayer(nn.Module):\n",
        "  def __init__(self , d_model , d_ff , dropout):\n",
        "    super().__init__()\n",
        "    self.feed_forward = nn.Sequential(\n",
        "        nn.Linear(d_model , d_ff), # [batch , seq_length , d_model] --> [batch , seq_length , d_ff]\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=dropout),\n",
        "        nn.Linear(d_ff , d_model),# [batch , seq_length , d_ff] --> [batch , seq_length , d_model]\n",
        "    )\n",
        "\n",
        "  def forward(self , x):\n",
        "    return self.feed_forward(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3W-CMxXnxYc"
      },
      "source": [
        "Multi-Head-Attention --> a mechanism that enhances the original attention mechanism by running it multiple times in parallel, each with its own learnable parameters.\n",
        "\n",
        "please watch \"https://www.youtube.com/watch?v=bCz4OMemCcA\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioTwprK1nwY6"
      },
      "outputs": [],
      "source": [
        "class MultiheadAttention(nn.Module):\n",
        "  def __init__(self , d_model , h , dropout):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.num_heads = h\n",
        "    self.d_k = d_model // h\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    assert d_model%h == 0\n",
        "\n",
        "    self.w_q = nn.Linear(d_model , d_model)\n",
        "    self.w_k = nn.Linear(d_model , d_model)\n",
        "    self.w_v = nn.Linear(d_model , d_model)\n",
        "\n",
        "    self.w_o = nn.Linear(h*self.d_k, d_model) # h*d_k == d_model\n",
        "\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "  @staticmethod\n",
        "  def attention(query , key , value ,mask , dropout):\n",
        "    d_k = query.shape[-1]\n",
        "    # remember --> key shape: [batch , num_heads , seq_length , d_k] , after transpose --> [batch , num_heads , d_k ,seq_length]\n",
        "    attention_scores = (query @ key.transpose(-2 , -1))/d_k**(0.5) # --> [batch , num_heads , seq_length,seq_length]\n",
        "    if mask is not None:\n",
        "      attention_scores.masked_fill_(mask==0 , -1e9)\n",
        "    attention_scores = attention_scores.softmax(dim=-1)\n",
        "\n",
        "    if dropout is not None:\n",
        "      attention_scores = dropout(attention_scores)\n",
        "\n",
        "    return attention_scores @ value , attention_scores # --> shapes -> [batch , num_heads , seq_length , d_k] , [batch , num_heads , seq_length,seq_length]\n",
        "\n",
        "  def forward(self, q,k,v, mask):\n",
        "    # q.shape --> [batch , seq_length , d_model]\n",
        "    query = self.w_q(q) # --> [batch , seq_length , d_model]\n",
        "    key = self.w_k(k) # --> [batch , seq_length , d_model]\n",
        "    value = self.w_v(v) # --> [batch , seq_length , d_model]\n",
        "\n",
        "    # [batch , seq_length , d_model] --> [batch , seq_length , num_heads , d_k] --> [batch , num_heads , seq_length , d_k]\n",
        "    query = query.view(query.shape[0] , query.shape[1] , self.num_heads , self.d_k).transpose(1,2)\n",
        "    key = key.view(key.shape[0] , key.shape[1] , self.num_heads , self.d_k).transpose(1,2)\n",
        "    value = value.view(value.shape[0] , value.shape[1] , self.num_heads , self.d_k).transpose(1,2)\n",
        "\n",
        "    x , attention_scores = MultiheadAttention.attention(query , key , value , mask , self.dropout)\n",
        "\n",
        "    # [batch , num_heads , seq_length , d_k] --> [batch , seq_length , num_heads , d_k] --> [batch , seq_length , d_model]\n",
        "    x = x.transpose(1,2).contiguous().view(x.shape[0] , -1 , self.d_model)\n",
        "\n",
        "    return self.w_o(x) # shape --> [batch , seq_length , d_model]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNsMh9VNwRHI"
      },
      "outputs": [],
      "source": [
        "class ResidualConnection(nn.Module):\n",
        "  def __init__(self , dropout):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.norm = LayerNormalization()\n",
        "\n",
        "  def forward(self, x , sublayer):\n",
        "    # sublayer is the prev layer\n",
        "    return x + self.dropout(sublayer(self.norm(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFenhHxx0cix"
      },
      "source": [
        "# Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDx3X7_638t7"
      },
      "source": [
        "In a Transformer architecture, the encoder's key and value tensors are used by the decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS7Ezr3VxAdt"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "  def __init__(self ,self_attention_block:MultiheadAttention , feed_forward_block:FeedForwardLayer, dropout):\n",
        "    super().__init__()\n",
        "    self.self_attention_block = self_attention_block\n",
        "    self.feed_forward_block = feed_forward_block\n",
        "    self.residual_connections = nn.ModuleList([ResidualConnection(dropout) for _ in range(2)])\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    # first we do the self attention --> making the words intereact with each other in the same sentences\n",
        "    x = self.residual_connections[0](x , lambda x: self.self_attention_block(x,x,x,mask))\n",
        "    x = self.residual_connections[1](x , self.feed_forward_block)\n",
        "\n",
        "    return x # now this will go to the decoder as key and value pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlY1GH4c3_cy"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self , layers:nn.Module):\n",
        "    super().__init__()\n",
        "    self.layers = layers\n",
        "    self.norm = LayerNormalization()\n",
        "\n",
        "  def forward(self , x ,mask):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x , mask)\n",
        "\n",
        "    return self.norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7t5-oYl4oXT"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self , self_attention_block:MultiheadAttention , cross_attention_block:MultiheadAttention , feed_forward_block:FeedForwardLayer, dropout):\n",
        "    super().__init__()\n",
        "    self.self_attention_block = self_attention_block\n",
        "    self.cross_attention_block = cross_attention_block\n",
        "    self.feed_forward_block = feed_forward_block\n",
        "    self.residual_connections = [ResidualConnection(dropout) for _ in range(3)]\n",
        "\n",
        "  def forward(self , x , encoder_output , encoder_mask,decoder_mask):\n",
        "    x = self.residual_connections[0](x , lambda x: self.self_attention_block(x,x,x,decoder_mask))\n",
        "    x = self.residual_connections[1](x , lambda x:self.cross_attention_block(x,encoder_output,encoder_output,encoder_mask)) # in this query will come from the masked multi-head-attention and the key and value will come from the encoder block output\n",
        "    x = self.residual_connections[2](x , self.feed_forward_block)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cyfWedY630j"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self , layers:nn.Module):\n",
        "    super().__init__()\n",
        "    self.layers = layers\n",
        "    self.norm = LayerNormalization()\n",
        "\n",
        "  def forward(self , x , encoder_output , encoder_mask , decoder_mask):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x , encoder_output , encoder_mask , decoder_mask)\n",
        "\n",
        "    return self.norm(x)\n",
        "\n",
        "# we expect the output form decoder to be --> [batch , seq_length , d_model]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Svwlv1Ej7v3_"
      },
      "outputs": [],
      "source": [
        "# now we want to map these words into the vocabulary\n",
        "class ProjectionLayer(nn.Module):\n",
        "  def __init__(self , d_model , vocab_size):\n",
        "    super().__init__()\n",
        "    self.proj = nn.Linear(d_model , vocab_size)\n",
        "\n",
        "  def forward(self , x):\n",
        "    # x.shape --> [batch , seq_length , d_model]\n",
        "    return torch.log_softmax(self.proj(x) ,dim=-1) # --> [batch , seq_length , vocab_size]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-t_qUY3-u5n"
      },
      "source": [
        "# Transformer Block  -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49H0Z_jT-llD"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self , encoder:Encoder , decoder:Decoder , src_emb:InputEmbedding , trg_emb:InputEmbedding , srcpos:PositionalEncoding , trgpos:PositionalEncoding , projection_layer:ProjectionLayer):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_emb = src_emb\n",
        "    self.trg_emb = trg_emb\n",
        "    self.srcpos = srcpos\n",
        "    self.trgpos = trgpos\n",
        "    self.projection_layer = projection_layer\n",
        "\n",
        "  def encode(self , src , src_mask):\n",
        "    src = self.srcpos(self.src_emb(src))\n",
        "    return self.encoder(src , src_mask)\n",
        "\n",
        "  def decode(self , trg , encoder_output , src_mask , trg_mask):\n",
        "    trg = self.trgpos(self.trg_emb(trg))\n",
        "    return self.decoder(trg , encoder_output , src_mask , trg_mask)\n",
        "\n",
        "  def project(self , x):\n",
        "    return self.projection_layer(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XD699IwVTVz"
      },
      "outputs": [],
      "source": [
        "def build_transformer(src_vocab_size , trg_vocab_size , src_seq_length , trg_seq_length , d_model , h , dropout , N , d_ff):\n",
        "  # create embedding layer for source and target\n",
        "  src_embed = InputEmbedding(d_model , src_vocab_size + 1).to(device)\n",
        "  trg_embed = InputEmbedding(d_model , trg_vocab_size + 1).to(device)\n",
        "\n",
        "  # create positional embedding layer\n",
        "  src_pos = PositionalEncoding(d_model , src_seq_length , dropout).to(device)\n",
        "  trg_pos = PositionalEncoding(d_model , trg_seq_length , dropout).to(device)\n",
        "\n",
        "  # create encoder block\n",
        "  encoder_blocks = []\n",
        "  for _ in range(N):\n",
        "    encoder_self_attention_block = MultiheadAttention(d_model , h , dropout).to(device)\n",
        "    feed_forward_block = FeedForwardLayer(d_model , d_ff , dropout).to(device)\n",
        "    encoder_blocks.append(EncoderBlock(encoder_self_attention_block , feed_forward_block , dropout))\n",
        "\n",
        "  # create decoder block\n",
        "  decoder_blocks = []\n",
        "  for _ in range(N):\n",
        "    decoder_self_attention_block = MultiheadAttention(d_model , h , dropout).to(device)\n",
        "    decoder_cross_attention_block = MultiheadAttention(d_model , h , dropout).to(device)\n",
        "    feed_forward_block = FeedForwardLayer(d_model , d_ff , dropout).to(device)\n",
        "    decoder_blocks.append(DecoderBlock(decoder_self_attention_block , decoder_cross_attention_block , feed_forward_block , dropout))\n",
        "\n",
        "  # create the encoder and decoder\n",
        "  encoder = Encoder(encoder_blocks).to(device)\n",
        "  decoder = Decoder(decoder_blocks).to(device)\n",
        "\n",
        "  # create projection layer\n",
        "  projection_layer = ProjectionLayer(d_model , trg_vocab_size).to(device)\n",
        "\n",
        "  # create transformer\n",
        "  transformer = Transformer(encoder , decoder , src_embed , trg_embed , src_pos , trg_pos , projection_layer).to(device)\n",
        "\n",
        "  # initialize parameters using xavier_uniform_\n",
        "  for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "      nn.init.xavier_uniform_(p)\n",
        "\n",
        "  return transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEv8cj3VyGvF",
        "outputId": "c66283b9-7bf2-45bc-e0f2-8cef3779ab33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-19 14:34:44--  https://downloads.tatoeba.org/exports/sentences.tar.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 204819212 (195M) [application/octet-stream]\n",
            "Saving to: ‘sentences.tar.bz2’\n",
            "\n",
            "sentences.tar.bz2   100%[===================>] 195.33M  15.8MB/s    in 13s     \n",
            "\n",
            "2025-06-19 14:34:59 (15.0 MB/s) - ‘sentences.tar.bz2’ saved [204819212/204819212]\n",
            "\n",
            "--2025-06-19 14:34:59--  https://downloads.tatoeba.org/exports/links.tar.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 139235583 (133M) [application/octet-stream]\n",
            "Saving to: ‘links.tar.bz2’\n",
            "\n",
            "links.tar.bz2       100%[===================>] 132.79M  24.5MB/s    in 6.5s    \n",
            "\n",
            "2025-06-19 14:35:06 (20.6 MB/s) - ‘links.tar.bz2’ saved [139235583/139235583]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -nc https://downloads.tatoeba.org/exports/sentences.tar.bz2\n",
        "!wget -nc https://downloads.tatoeba.org/exports/links.tar.bz2\n",
        "!tar -xf sentences.tar.bz2\n",
        "!tar -xf links.tar.bz2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP02uWRHyHYL",
        "outputId": "ebbca2bb-af9a-45bf-9a41-ff681da04983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    src      tgt  id_en lang_en                     text_en    id_hi lang_hi  \\\n",
            "0  1277  3792910   1277     eng      I have to go to sleep.  3792910     hin   \n",
            "1  1282   485968   1282     eng          Muiriel is 20 now.   485968     hin   \n",
            "2  1282  2060319   1282     eng          Muiriel is 20 now.  2060319     hin   \n",
            "3  1283   451291   1283     eng  The password is \"Muiriel\".   451291     hin   \n",
            "4  1283   451292   1283     eng  The password is \"Muiriel\".   451292     hin   \n",
            "\n",
            "                            text_hi  \n",
            "0                     मुझे सोना है।  \n",
            "1  म्यूरियल अब बीस साल की हो गई है।  \n",
            "2        म्यूरियल अब बीस साल की है।  \n",
            "3              कूटशब्द \"Muriel\" है।  \n",
            "4              पासवर्ड \"Muriel\" है।  \n",
            "Found 13182 English–Hindi sentence pairs\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"sentences.csv\", sep=\"\\t\", header=None, names=[\"id\", \"lang\", \"text\"])\n",
        "# print(df.head())\n",
        "\n",
        "df_eng = df[df['lang']=='eng']\n",
        "df_hindi = df[df['lang'] == 'hin']\n",
        "\n",
        "# print(df_eng.head())\n",
        "# print(df_hindi.head())\n",
        "\n",
        "links = pd.read_csv('links.csv' , sep='\\t' , header=None , names=[\"src\" , \"tgt\"]) # loads the links bettwen the target\n",
        "# print(links.head())\n",
        "\n",
        "# Merge to get aligned pairs\n",
        "merged = links.merge(df_eng, left_on=\"src\", right_on=\"id\").merge(df_hindi, left_on=\"tgt\", right_on=\"id\", suffixes=('_en', '_hi'))\n",
        "print(merged.head())\n",
        "\n",
        "en_sentences = merged['text_en'].tolist()\n",
        "hi_sentences = merged['text_hi'].tolist()\n",
        "\n",
        "print(f\"Found {len(en_sentences)} English–Hindi sentence pairs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgyeDvj30WGp"
      },
      "outputs": [],
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# converting the lines to txt file\n",
        "with open(\"eng.txt\" , \"w\") as f:\n",
        "  for line in en_sentences:\n",
        "    f.write(line.strip() + \"\\n\")\n",
        "\n",
        "with open(\"hindi.txt\" , \"w\") as f:\n",
        "  for line in hi_sentences:\n",
        "    f.write(line.strip() + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTdjXPig0D8M"
      },
      "outputs": [],
      "source": [
        "def train_tokenizer(file_path:Path , vocab_size:int , output_path:Path):\n",
        "  tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
        "  tokenizer.pre_tokenizer = Whitespace()\n",
        "  trainer = WordLevelTrainer(vocab_size=vocab_size , special_tokens=[\"[PAD]\" , \"[SOS]\" , \"[EOS]\" , \"[UNK]\"] , min_frequency=2)\n",
        "  tokenizer.train([file_path] , trainer)\n",
        "  tokenizer.save(output_path)\n",
        "\n",
        "train_tokenizer(\"eng.txt\" , 8000 , \"en-tokenize.json\")\n",
        "train_tokenizer(\"hindi.txt\" , 8000 , \"hindi-tokenize.json\")\n",
        "\n",
        "eng_tokenizer = Tokenizer.from_file(\"en-tokenize.json\")\n",
        "hindi_tokenizer = Tokenizer.from_file(\"hindi-tokenize.json\")\n",
        "\n",
        "VOCAB_SIZE_ENG = eng_tokenizer.get_vocab_size()     # 5912\n",
        "VOCAB_SIZE_HINDI = hindi_tokenizer.get_vocab_size() # 7070"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZA780iA4Sgz"
      },
      "source": [
        "creating a dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N86ewtBO8yNU",
        "outputId": "93aa2e28-030e-4bb2-ddfa-949ebfc565b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0., 1., 1., 1., 1.],\n",
            "         [0., 0., 1., 1., 1.],\n",
            "         [0., 0., 0., 1., 1.],\n",
            "         [0., 0., 0., 0., 1.],\n",
            "         [0., 0., 0., 0., 0.]]])\n",
            "torch.Size([1, 5, 5])\n",
            "tensor([[[1, 0, 0, 0, 0],\n",
            "         [1, 1, 0, 0, 0],\n",
            "         [1, 1, 1, 0, 0],\n",
            "         [1, 1, 1, 1, 0],\n",
            "         [1, 1, 1, 1, 1]]], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "seq_length_for_example = 5\n",
        "\n",
        "a = torch.triu(torch.ones((1,seq_length_for_example,seq_length_for_example)) , diagonal=1)\n",
        "print(a)\n",
        "print(a.shape)\n",
        "\n",
        "# to create a proper mask for decoder\n",
        "print((a == 0).int())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s20Vf5wVyjOr",
        "outputId": "e15457df-9a0c-4f3d-ef2f-9f208a6f02c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing dataloader...\n",
            "Processing batch 0...\n",
            "Encoder input shape: torch.Size([32, 100])\n",
            "Decoder input shape: torch.Size([32, 100])\n",
            "Label shape: torch.Size([32, 100])\n",
            "Encoder mask shape: torch.Size([32, 1, 1, 100])\n",
            "Decoder mask shape: torch.Size([32, 1, 100, 100])\n",
            "Dataloader test completed successfully!\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "ds = [\n",
        "    {\"translation\": {\"en\": en, \"hi\": hi}} for en, hi in zip(en_sentences, hi_sentences)\n",
        "]\n",
        "\n",
        "def casual_mask(size):\n",
        "    mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n",
        "    return mask == 0\n",
        "\n",
        "class Eng_Hindi_Dataset(Dataset):\n",
        "    def __init__(self, ds, device, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_length):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.ds = ds\n",
        "        self.src_lang = src_lang\n",
        "        self.tgt_lang = tgt_lang\n",
        "        self.tokenizer_src = tokenizer_src\n",
        "        self.tokenizer_tgt = tokenizer_tgt\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "        # Get special token IDs and validate them\n",
        "        self.sos_token_src = self._get_token_id(tokenizer_src, \"[SOS]\")\n",
        "        self.eos_token_src = self._get_token_id(tokenizer_src, \"[EOS]\")\n",
        "        self.pad_token_src = self._get_token_id(tokenizer_src, \"[PAD]\")\n",
        "\n",
        "        self.sos_token_tgt = self._get_token_id(tokenizer_tgt, \"[SOS]\")\n",
        "        self.eos_token_tgt = self._get_token_id(tokenizer_tgt, \"[EOS]\")\n",
        "        self.pad_token_tgt = self._get_token_id(tokenizer_tgt, \"[PAD]\")\n",
        "\n",
        "        # Store vocab sizes for validation\n",
        "        self.src_vocab_size = tokenizer_src.get_vocab_size()\n",
        "        self.tgt_vocab_size = tokenizer_tgt.get_vocab_size()\n",
        "\n",
        "    def _get_token_id(self, tokenizer, token):\n",
        "        \"\"\"Helper method to get token ID with error handling\"\"\"\n",
        "        token_id = tokenizer.token_to_id(token)\n",
        "        if token_id is None:\n",
        "            raise ValueError(f\"Token '{token}' not found in tokenizer vocabulary\")\n",
        "        return token_id\n",
        "\n",
        "    def _validate_token_ids(self, token_ids, vocab_size, tokenizer_name):\n",
        "        \"\"\"Validate that all token IDs are within vocabulary range\"\"\"\n",
        "        if not token_ids:\n",
        "          return\n",
        "\n",
        "        min_id = min(token_ids)\n",
        "        max_id = max(token_ids)\n",
        "        if min_id < 0:\n",
        "             raise ValueError(f\"Negative token ID {min_id} found in {tokenizer_name} tokens.\")\n",
        "        if max_id >= vocab_size:\n",
        "            raise ValueError(f\"Token ID {max_id} exceeds {tokenizer_name} vocabulary size {vocab_size}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        src_target_pair = self.ds[index]\n",
        "\n",
        "        src_text = src_target_pair[\"translation\"][self.src_lang]\n",
        "        tgt_text = src_target_pair[\"translation\"][self.tgt_lang]\n",
        "\n",
        "        # Encode texts\n",
        "        enc_input_tokens = self.tokenizer_src.encode(src_text).ids\n",
        "        dec_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids\n",
        "\n",
        "        # Validate token IDs are within vocabulary range\n",
        "        self._validate_token_ids(enc_input_tokens, self.src_vocab_size, \"source\")\n",
        "        self._validate_token_ids(dec_input_tokens, self.tgt_vocab_size, \"target\")\n",
        "\n",
        "        # Calculate padding\n",
        "        enc_num_pad = self.seq_length - len(enc_input_tokens) - 2  # -2 for SOS and EOS\n",
        "        dec_num_pad = self.seq_length - len(dec_input_tokens) - 1  # -1 for EOS\n",
        "\n",
        "        if enc_num_pad < 0 or dec_num_pad < 0:\n",
        "            raise ValueError(f\"Sentence is too long. Source: {len(enc_input_tokens)}, Target: {len(dec_input_tokens)}, Max length: {self.seq_length}\")\n",
        "\n",
        "        # Create encoder input: [SOS] + tokens + [EOS] + padding\n",
        "        encoder_input = torch.cat([\n",
        "            torch.tensor([self.sos_token_src], dtype=torch.long),\n",
        "            torch.tensor(enc_input_tokens, dtype=torch.long),\n",
        "            torch.tensor([self.eos_token_src], dtype=torch.long),\n",
        "            torch.tensor([self.pad_token_src] * enc_num_pad, dtype=torch.long),\n",
        "        ])\n",
        "\n",
        "        # Create decoder input: [SOS] + tokens + padding\n",
        "        decoder_input = torch.cat([\n",
        "            torch.tensor([self.sos_token_tgt], dtype=torch.long),\n",
        "            torch.tensor(dec_input_tokens, dtype=torch.long),\n",
        "            torch.tensor([self.pad_token_tgt] * dec_num_pad, dtype=torch.long),\n",
        "        ])\n",
        "\n",
        "        # Create labels: tokens + [EOS] + padding\n",
        "        label = torch.cat([\n",
        "            torch.tensor(dec_input_tokens, dtype=torch.long),\n",
        "            torch.tensor([self.eos_token_tgt], dtype=torch.long),\n",
        "            torch.tensor([self.pad_token_tgt] * dec_num_pad, dtype=torch.long),\n",
        "        ])\n",
        "\n",
        "        # Verify all tensors have correct length\n",
        "        assert encoder_input.size(0) == self.seq_length, f\"Encoder input size: {encoder_input.size(0)}, expected: {self.seq_length}\"\n",
        "        assert decoder_input.size(0) == self.seq_length, f\"Decoder input size: {decoder_input.size(0)}, expected: {self.seq_length}\"\n",
        "        assert label.size(0) == self.seq_length, f\"Label size: {label.size(0)}, expected: {self.seq_length}\"\n",
        "\n",
        "        # Create masks\n",
        "        encoder_mask = (encoder_input != self.pad_token_src).unsqueeze(0).unsqueeze(0).int()\n",
        "\n",
        "        # Decoder mask: padding mask AND causal mask\n",
        "        decoder_padding_mask = (decoder_input != self.pad_token_tgt).unsqueeze(0).int()\n",
        "        decoder_causal_mask = casual_mask(decoder_input.size(0)).int()\n",
        "        decoder_mask = decoder_padding_mask & decoder_causal_mask\n",
        "\n",
        "        return {\n",
        "            \"encoder_input\": encoder_input.to(device),\n",
        "            \"decoder_input\": decoder_input.to(device),\n",
        "            \"label\": label.to(device),\n",
        "            \"encoder_mask\": encoder_mask.to(self.device),\n",
        "            \"decoder_mask\": decoder_mask.to(self.device),\n",
        "            \"src_text\": src_text,\n",
        "            \"tgt_text\": tgt_text,\n",
        "        }\n",
        "\n",
        "\n",
        "# Configuration\n",
        "BATCH_SIZE = 32\n",
        "SEQ_LENGTH = 100\n",
        "\n",
        "# Create dataset\n",
        "dataset = Eng_Hindi_Dataset(ds, device, eng_tokenizer, hindi_tokenizer, \"en\", \"hi\", SEQ_LENGTH)\n",
        "\n",
        "\n",
        "# Split dataset\n",
        "n = int(0.8 * len(dataset))\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [n, len(dataset) - n])\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True , pin_memory=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Test the dataloader\n",
        "print(\"Testing dataloader...\")\n",
        "for i, batch in enumerate(train_dataloader):\n",
        "    if i >= 5: # Print for a few batches to see if the issue is consistent\n",
        "        break\n",
        "    print(f\"Processing batch {i}...\")\n",
        "    print(f\"Encoder input shape: {batch['encoder_input'].shape}\")\n",
        "    print(f\"Decoder input shape: {batch['decoder_input'].shape}\")\n",
        "    print(f\"Label shape: {batch['label'].shape}\")\n",
        "    print(f\"Encoder mask shape: {batch['encoder_mask'].shape}\")\n",
        "    print(f\"Decoder mask shape: {batch['decoder_mask'].shape}\")\n",
        "\n",
        "    # The added print statements in __getitem__ will also execute here for each item in the batch\n",
        "    break # Break after the first batch to see the output from the first item\n",
        "print(\"Dataloader test completed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLBjZlOrBhNd"
      },
      "source": [
        "Training the transformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE_ENG = 5912  # eng_tokenizer.get_vocab_size()\n",
        "VOCAB_SIZE_HINDI = 7070 # hindi_tokenizer.get_vocab_size()\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 100\n",
        "LR = 10**-4\n",
        "D_model = 128//2\n",
        "D_ff = 512//2\n",
        "H = 4 # no of heads\n",
        "N = 3 # no of layers\n",
        "DROPOUT = 0.1\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "losses = [0]\n",
        "\n",
        "model = build_transformer(VOCAB_SIZE_ENG , VOCAB_SIZE_HINDI  , SEQ_LENGTH , SEQ_LENGTH , D_model , H , DROPOUT , N , D_ff).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters() , LR)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=hindi_tokenizer.token_to_id(\"[PAD]\") , label_smoothing=0.1).to(device)"
      ],
      "metadata": {
        "id": "zDvXhILWxSxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "\n",
        "# Configs\n",
        "ACCUM_STEPS = 4\n",
        "CHECKPOINT_PATH = 'checkpoint.pt'\n",
        "BEST_MODEL_PATH = 'best_model.pt'\n",
        "\n",
        "# Initialize\n",
        "start_epoch = 0\n",
        "NUM_EPOCHS = 100\n",
        "losses = []\n",
        "best_loss = float('inf')  # Track best loss\n",
        "\n",
        "# Resume checkpoint if exists\n",
        "if os.path.exists(CHECKPOINT_PATH):\n",
        "    print(\"🔁 Resuming from checkpoint...\")\n",
        "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    losses = checkpoint['losses']\n",
        "    best_loss = checkpoint.get('best_loss', float('inf'))\n",
        "\n",
        "# Training loop\n",
        "for epoch in tqdm(range(start_epoch, NUM_EPOCHS), desc=\"Training\"):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        encoder_input = batch[\"encoder_input\"].long().to(device)\n",
        "        decoder_input = batch[\"decoder_input\"].long().to(device)\n",
        "        label = batch[\"label\"].long().to(device)\n",
        "        encoder_mask = batch[\"encoder_mask\"].to(device)\n",
        "        decoder_mask = batch[\"decoder_mask\"].to(device)\n",
        "\n",
        "        encoder_output = model.encode(encoder_input, encoder_mask)\n",
        "        decoder_output = model.decode(decoder_input, encoder_output, encoder_mask, decoder_mask)\n",
        "        proj_output = model.projection_layer(decoder_output)\n",
        "\n",
        "        loss = criterion(proj_output.reshape(-1, proj_output.size(-1)), label.reshape(-1))\n",
        "        loss = loss / ACCUM_STEPS\n",
        "        loss.backward()\n",
        "\n",
        "        if (i + 1) % ACCUM_STEPS == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataloader)\n",
        "    losses.append(epoch_loss)\n",
        "    print(f\"Epoch {epoch} || Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    # Save regular checkpoint\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'losses': losses,\n",
        "        'best_loss': best_loss\n",
        "    }, CHECKPOINT_PATH)\n",
        "\n",
        "    # Save only best model\n",
        "    if epoch_loss < best_loss:\n",
        "        best_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
        "        print(f\"🏆 Best model saved at epoch {epoch} with loss {best_loss:.4f}\")\n",
        "\n",
        "print(f\"✅ Final Loss: {losses[-1]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ad30cb07a7fe4208b025685fefdd6519",
            "a1b40aea17534c13bf682e301b86d1f6",
            "8cc1e1917d7a49efb1b8fb26c67457f8",
            "1b161862ac854841a5806f362af97b94",
            "02c3fe292dad4159acb2ae742762203c",
            "c7b328057e4a4c359f49bc46e47b96f5",
            "f4f382d1807d4d50bb0fbc18ac3de579",
            "31fccecb981544e391209b347c067b28",
            "959829f8d15544b2a67f9cad86f971d6",
            "d003d2359efa4fa9b76abec067767451",
            "755677691f2f43029ce1c33c4bb6a76f"
          ]
        },
        "id": "rrCqoCU8G-dr",
        "outputId": "86d91e81-71e6-4b7d-eb2e-04ee1efa895f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔁 Resuming from checkpoint...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad30cb07a7fe4208b025685fefdd6519"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 || Loss: 0.6960\n",
            "🏆 Best model saved at epoch 50 with loss 0.6960\n",
            "Epoch 51 || Loss: 0.6964\n",
            "Epoch 52 || Loss: 0.6950\n",
            "🏆 Best model saved at epoch 52 with loss 0.6950\n",
            "Epoch 53 || Loss: 0.6935\n",
            "🏆 Best model saved at epoch 53 with loss 0.6935\n",
            "Epoch 54 || Loss: 0.6931\n",
            "🏆 Best model saved at epoch 54 with loss 0.6931\n",
            "Epoch 55 || Loss: 0.6925\n",
            "🏆 Best model saved at epoch 55 with loss 0.6925\n",
            "Epoch 56 || Loss: 0.6926\n",
            "Epoch 57 || Loss: 0.6900\n",
            "🏆 Best model saved at epoch 57 with loss 0.6900\n",
            "Epoch 58 || Loss: 0.6906\n",
            "Epoch 59 || Loss: 0.6900\n",
            "🏆 Best model saved at epoch 59 with loss 0.6900\n",
            "Epoch 60 || Loss: 0.6885\n",
            "🏆 Best model saved at epoch 60 with loss 0.6885\n",
            "Epoch 61 || Loss: 0.6872\n",
            "🏆 Best model saved at epoch 61 with loss 0.6872\n",
            "Epoch 62 || Loss: 0.6864\n",
            "🏆 Best model saved at epoch 62 with loss 0.6864\n",
            "Epoch 63 || Loss: 0.6845\n",
            "🏆 Best model saved at epoch 63 with loss 0.6845\n",
            "Epoch 64 || Loss: 0.6846\n",
            "Epoch 65 || Loss: 0.6848\n",
            "Epoch 66 || Loss: 0.6844\n",
            "🏆 Best model saved at epoch 66 with loss 0.6844\n",
            "Epoch 67 || Loss: 0.6826\n",
            "🏆 Best model saved at epoch 67 with loss 0.6826\n",
            "Epoch 68 || Loss: 0.6828\n",
            "Epoch 69 || Loss: 0.6813\n",
            "🏆 Best model saved at epoch 69 with loss 0.6813\n",
            "Epoch 70 || Loss: 0.6814\n",
            "Epoch 71 || Loss: 0.6802\n",
            "🏆 Best model saved at epoch 71 with loss 0.6802\n",
            "Epoch 72 || Loss: 0.6793\n",
            "🏆 Best model saved at epoch 72 with loss 0.6793\n",
            "Epoch 73 || Loss: 0.6784\n",
            "🏆 Best model saved at epoch 73 with loss 0.6784\n",
            "Epoch 74 || Loss: 0.6780\n",
            "🏆 Best model saved at epoch 74 with loss 0.6780\n",
            "Epoch 75 || Loss: 0.6754\n",
            "🏆 Best model saved at epoch 75 with loss 0.6754\n",
            "Epoch 76 || Loss: 0.6757\n",
            "Epoch 77 || Loss: 0.6762\n",
            "Epoch 78 || Loss: 0.6755\n",
            "Epoch 79 || Loss: 0.6742\n",
            "🏆 Best model saved at epoch 79 with loss 0.6742\n",
            "Epoch 80 || Loss: 0.6738\n",
            "🏆 Best model saved at epoch 80 with loss 0.6738\n",
            "Epoch 81 || Loss: 0.6734\n",
            "🏆 Best model saved at epoch 81 with loss 0.6734\n",
            "Epoch 82 || Loss: 0.6724\n",
            "🏆 Best model saved at epoch 82 with loss 0.6724\n",
            "Epoch 83 || Loss: 0.6721\n",
            "🏆 Best model saved at epoch 83 with loss 0.6721\n",
            "Epoch 84 || Loss: 0.6711\n",
            "🏆 Best model saved at epoch 84 with loss 0.6711\n",
            "Epoch 85 || Loss: 0.6715\n",
            "Epoch 86 || Loss: 0.6707\n",
            "🏆 Best model saved at epoch 86 with loss 0.6707\n",
            "Epoch 87 || Loss: 0.6683\n",
            "🏆 Best model saved at epoch 87 with loss 0.6683\n",
            "Epoch 88 || Loss: 0.6681\n",
            "🏆 Best model saved at epoch 88 with loss 0.6681\n",
            "Epoch 89 || Loss: 0.6682\n",
            "Epoch 90 || Loss: 0.6671\n",
            "🏆 Best model saved at epoch 90 with loss 0.6671\n",
            "Epoch 91 || Loss: 0.6678\n",
            "Epoch 92 || Loss: 0.6662\n",
            "🏆 Best model saved at epoch 92 with loss 0.6662\n",
            "Epoch 93 || Loss: 0.6653\n",
            "🏆 Best model saved at epoch 93 with loss 0.6653\n",
            "Epoch 94 || Loss: 0.6646\n",
            "🏆 Best model saved at epoch 94 with loss 0.6646\n",
            "Epoch 95 || Loss: 0.6652\n",
            "Epoch 96 || Loss: 0.6637\n",
            "🏆 Best model saved at epoch 96 with loss 0.6637\n",
            "Epoch 97 || Loss: 0.6632\n",
            "🏆 Best model saved at epoch 97 with loss 0.6632\n",
            "Epoch 98 || Loss: 0.6624\n",
            "🏆 Best model saved at epoch 98 with loss 0.6624\n",
            "Epoch 99 || Loss: 0.6612\n",
            "🏆 Best model saved at epoch 99 with loss 0.6612\n",
            "✅ Final Loss: 0.6612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiVzOJdgV5xP"
      },
      "outputs": [],
      "source": [
        "def translate(model , src , src_tokenizer , tgt_tokenizer , seq_length , device):\n",
        "  model.eval()\n",
        "  src_ids = src_tokenizer.encode(src).ids\n",
        "\n",
        "  src_tokens = [src_tokenizer.token_to_id(\"[SOS]\")] + src_ids + [src_tokenizer.token_to_id(\"[EOS]\")]\n",
        "  src_tokens += [src_tokenizer.token_to_id(\"[PAD]\")] * (seq_length - len(src_tokens))\n",
        "  encodr_input = torch.tensor(src_tokens , dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "  encoder_mask = (encodr_input != src_tokenizer.token_to_id(\"[PAD]\")).unsqueeze(0).unsqueeze(0).int().to(device)\n",
        "\n",
        "  tgt_tokens = [tgt_tokenizer.token_to_id(\"[SOS]\")]\n",
        "  for _ in range(seq_length):\n",
        "    decoder_input = torch.tensor(tgt_tokens , dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    tgt_mask = (decoder_input != tgt_tokenizer.token_to_id(\"[PAD]\")).unsqueeze(0).int().to(device)\n",
        "    tgt_casual_mask = casual_mask(decoder_input.size(1)).int().to(device)\n",
        "\n",
        "    decoder_mask = tgt_mask & tgt_casual_mask\n",
        "\n",
        "    # forward pass\n",
        "    with torch.no_grad():\n",
        "      encoder_output_translated = model.encode(encodr_input , encoder_mask)\n",
        "      output = model.decode(decoder_input , encoder_output_translated , encoder_mask , decoder_mask)\n",
        "\n",
        "\n",
        "    next_token_logits = output[0 , -1 , :]\n",
        "\n",
        "    # Apply softmax to the logits before sampling to get probabilities\n",
        "    probabilities = torch.softmax(next_token_logits, dim=-1)\n",
        "    next_token_id = torch.multinomial(probabilities , num_samples=1).item()\n",
        "\n",
        "    tgt_tokens.append(next_token_id)\n",
        "\n",
        "    # Use token_to_id instead of _get_token_id\n",
        "    if next_token_id == tgt_tokenizer.token_to_id(\"[EOS]\"):\n",
        "      break\n",
        "\n",
        "  decoder_token = tgt_tokenizer.decode(tgt_tokens[1:])\n",
        "  return decoder_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmKFZdbtyGs1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73304a21-d007-4d04-db1d-bfbeaf5418d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "मैंने मैंने मैंने तो सकता साथ तुम्हें क्या सकता तो उसे सकता तो मैंने मैंने से मैंने को ! - तुम्हें सकता साथ मैंने । एक साथ तो थे ने सकता तो साथ थे ने हैं तुम क्या ने क्या कर मैंने साथ कर मैंने तो आप क्या तुम्हें तो ने तो मैंने तो मैंने मैंने बात थे रही तो मैंने साथ तुम्हें मेरा तुम्हें मैंने मैंने\n"
          ]
        }
      ],
      "source": [
        "print(translate(model , \"I am hungry\" , eng_tokenizer , hindi_tokenizer , SEQ_LENGTH , device))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "cpu_losses = [loss.item() if isinstance(loss, torch.Tensor) else loss for loss in losses]\n",
        "\n",
        "plt.plot(cpu_losses)\n",
        "plt.xlabel(\"Batch Iteration\") # Optional: Add labels for clarity\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss over Iterations\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6dAGvv7lxjqO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "e83092ca-ac7e-4936-a493-812744bc2981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install nbstripout\n",
        "\n",
        "!nbstripout transformer(attention is all you need).ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SDETl-_Yx1W",
        "outputId": "6a0cd9f5-f574-47b2-e3f2-1a54a5cbd5fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nbstripout\n",
            "  Downloading nbstripout-0.8.1-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from nbstripout) (5.10.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->nbstripout) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->nbstripout) (4.24.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat->nbstripout) (5.8.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.11/dist-packages (from nbformat->nbstripout) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (0.25.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->nbstripout) (4.3.8)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat->nbstripout) (4.14.0)\n",
            "Downloading nbstripout-0.8.1-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: nbstripout\n",
            "Successfully installed nbstripout-0.8.1\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `nbstripout transformer(attention is all you need).ipynb'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMzQm17TNjXj75A/z3n+9I0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ad30cb07a7fe4208b025685fefdd6519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1b40aea17534c13bf682e301b86d1f6",
              "IPY_MODEL_8cc1e1917d7a49efb1b8fb26c67457f8",
              "IPY_MODEL_1b161862ac854841a5806f362af97b94"
            ],
            "layout": "IPY_MODEL_02c3fe292dad4159acb2ae742762203c"
          }
        },
        "a1b40aea17534c13bf682e301b86d1f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7b328057e4a4c359f49bc46e47b96f5",
            "placeholder": "​",
            "style": "IPY_MODEL_f4f382d1807d4d50bb0fbc18ac3de579",
            "value": "Training: 100%"
          }
        },
        "8cc1e1917d7a49efb1b8fb26c67457f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31fccecb981544e391209b347c067b28",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_959829f8d15544b2a67f9cad86f971d6",
            "value": 50
          }
        },
        "1b161862ac854841a5806f362af97b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d003d2359efa4fa9b76abec067767451",
            "placeholder": "​",
            "style": "IPY_MODEL_755677691f2f43029ce1c33c4bb6a76f",
            "value": " 50/50 [16:07&lt;00:00, 19.61s/it]"
          }
        },
        "02c3fe292dad4159acb2ae742762203c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7b328057e4a4c359f49bc46e47b96f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4f382d1807d4d50bb0fbc18ac3de579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31fccecb981544e391209b347c067b28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "959829f8d15544b2a67f9cad86f971d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d003d2359efa4fa9b76abec067767451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "755677691f2f43029ce1c33c4bb6a76f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}